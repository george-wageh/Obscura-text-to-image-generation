{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2nA3K5RoEqTq"},"outputs":[],"source":["!pip install --upgrade --no-cache-dir gdown\n","!pip install diffusers\n","!pip install datasets\n","!pip install peft\n","!pip install gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u1t9cHr5W6mV"},"outputs":[],"source":["import gdown\n","url = \"https://drive.google.com/uc?id=1mR_axgYLVaFzLJ3QZw8NZlTwk6WTpcXW\"\n","output = \"/content/code.zip\"\n","gdown.download(url, output, quiet=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q7uMoRy9E6cD"},"outputs":[],"source":["import zipfile\n","import os\n","\n","zip_file_path = '/content/code.zip'\n","extract_folder_path = '/content/'\n","\n","# Check if the zip file exists\n","if os.path.exists(zip_file_path):\n","    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_folder_path)\n","else:\n","    print(\"The specified zip file does not exist.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XCcIvh1ZJj0r"},"outputs":[],"source":["import torch\n","device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZfTLk3MZJbyF"},"outputs":[],"source":["from models import Diffusion\n","d = Diffusion(device , \"LMSD\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wj6djMddkKxQ"},"outputs":[],"source":["!pip install -U git+https://github.com/openai/CLIP.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ecT9DFR0kLP4","outputId":"35602181-73cc-4de5-f9a8-2cc0af206fce"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|████████████████████████████████████████| 338M/338M [00:02<00:00, 128MiB/s]\n"]}],"source":["import torch\n","import clip\n","from PIL import Image\n","model, preprocess = clip.load('ViT-B/32')\n","model = model.to(device)\n","def get_clip_score(image, text):\n","# Load the pre-trained CLIP model and the image\n","\n","    # Preprocess the image and tokenize the text\n","    image_input = preprocess(image).unsqueeze(0)\n","    text_input = clip.tokenize([text] , truncate=True)\n","\n","    # Move the inputs to GPU if available\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    image_input = image_input.to(device)\n","    text_input = text_input.to(device)\n","\n","\n","    # Generate embeddings for the image and text\n","    with torch.no_grad():\n","        image_features = model.encode_image(image_input)\n","        text_features = model.encode_text(text_input)\n","\n","    # Normalize the features\n","    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n","    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n","\n","    # Calculate the cosine similarity to get the CLIP score\n","    clip_score = torch.matmul(image_features, text_features.T).item()\n","\n","    return clip_score\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jrPEGaMBl6pG"},"outputs":[],"source":["from datasets import load_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ufZ25mDkOB2"},"outputs":[],"source":["evaluate_dataset = load_dataset(\"nateraw/parti-prompts\", split=\"train\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jh3HyIrFkP3X"},"outputs":[],"source":["arrScores = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2l52Cd1EkRbm"},"outputs":[],"source":["for i in range(int(len(evaluate_dataset)//5)):\n","  Prompts = []\n","  for j in range(5):\n","    Prompts.append(evaluate_dataset[i*5 + j][\"Prompt\"])\n","  ims,_ = d.generate(Prompts , scale_guide=11, timesteps = 50 ,dataset_ = \"None\", resolution=(512,512))\n","  for j in range(5):\n","    score = get_clip_score(ims[j], Prompts[j])\n","    sample = evaluate_dataset[i*5 + j]\n","    s = {\"Prompt\" : sample[\"Prompt\"] ,\"image\" : ims[j], \"Category\" :sample[\"Category\"] , \"Challenge\" :sample[\"Challenge\"] , \"CLIP Score\":score }\n","    arrScores.append(s)\n","    print(f\"{s}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oEBeifnEF-i3"},"outputs":[],"source":["categories ={}\n","challenges ={}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U6CyNwNgGHcF"},"outputs":[],"source":["for i in range(len(arrScores)):\n","  if (arrScores[i][\"Category\"] not in categories):\n","    categories[arrScores[i][\"Category\"]]=0\n","  if (arrScores[i][\"Challenge\"] not in challenges):\n","    challenges[arrScores[i][\"Challenge\"]]=0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5WO9oqsGI1M"},"outputs":[],"source":["for key in categories:\n","  sum_ = 0\n","  len_ = 0\n","  for i in range(len(arrScores)):\n","    if (arrScores[i][\"Category\"] == key):\n","      sum_ += arrScores[i][\"CLIP Score\"]\n","      len_+=1\n","  categories[key] = sum_/len_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8t7M40DJGJyW"},"outputs":[],"source":["for key in challenges:\n","  sum_ = 0\n","  len_ = 0\n","  for i in range(len(arrScores)):\n","    if (arrScores[i][\"Challenge\"] == key):\n","      sum_ += arrScores[i][\"CLIP Score\"]\n","      len_+=1\n","  challenges[key] = sum_/len_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ri91lzmlJd5C"},"outputs":[],"source":["sum_ = 0\n","len_ = 0\n","for i in range(len(arrScores)):\n","    sum_ += arrScores[i][\"CLIP Score\"]\n","    len_+=1\n","sum_/len_"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}